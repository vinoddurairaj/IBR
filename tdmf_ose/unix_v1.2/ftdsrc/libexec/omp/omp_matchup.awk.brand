#!/usr/bin/gawk -f
###############################################################################
#
# LICENSED MATERIALS / PROPERTY OF IBM
#
# Offline Migration Package (OMP)   Version %VERSION%
#
# (c) Copyright %COMPANYNAME%  %COPYRIGHTYEAR 2007%.  All Rights Reserved.
#
# The source code for this program is not published or otherwise
# divested of its trade secrets, irrespective of what has been
# deposited with the U.S. Copyright Office.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with %COMPANYNAME%
#
# $Id: omp_matchup.awk.brand,v 1.2 2008/12/28 10:12:16 naat0 Exp $
#
# Function: Validate and Generate Configuration Files
#
###############################################################################

function NoStdOutput()
{
    discard_output = discard_output " no_std "
}

function NoLogOutput()
{
    discard_output = discard_output " no_log "
}

function Display( msgcode, arg1, arg2, arg3,    exitcode, message, idx, timestamp, severity )
{
    exitcode = EC_ERROR
    if (msgcode == "MissingField") # field, file
    {
	message[0] = "Cannot find field \"" arg1 "\" in file \"" arg2 "\""
    }
    else if (msgcode == "ReadError") # file, linecnt
    {
	if (arg2 == 0)
	{
	    message[0] = "Unable to open or read file \"" arg1 "\"." 
	}
	else
	{
	    message[0] = "Unexpected read error on file \"" arg1 "\" around line " arg2 "." 
	}
    }
    else if (msgcode == "InvalidColName") # colname, file
    {
	message[0] = "Column \"" arg1 "\" in \"" arg2 "\" is not identified as a source or target column."
    }
    else if (msgcode == "NoSrcCols") # file
    {
	message[0] = "No source matching column names found in \"" arg1 "\"."
    }
    else if (msgcode == "NoTgtCols") # file
    {
	message[0] = "No target matching column names found in \"" arg1 "\"."
    }
    else if (msgcode == "CrossCheck") # file
    {
	exitcode = EC_WARN
	message[0] = "Cross checking source devices against target devices"
	message[1] = "will not work becasue target matching column"
	message[2] = "\"" arg1 "\" does not exist in the target device file."
    }
    else if (msgcode == "NoCrossCheck") # file
    {
	exitcode = EC_WARN
	message[0] = "Cannot cross check source devices against target devices"
	message[1] = "becasue matching columns do not agree."
    }
    else if (msgcode == "NoCsvFiles")
    {
	message[0] = "No source or target files were created."
    }
    else if (msgcode == "DiskAlreadyUsed") # key, file
    {
	message[0] = "Disk \"" arg1 "\" already used from file \"" arg2 "\"."
    }
    else if (msgcode == "DiskNotFound") # key, file
    {
	message[0] = "Disk \"" arg1 "\" not found in file \"" arg2 "\"."
    }
    else if (msgcode == "DuplicateDisk") # key, file
    {
	message[0] = "Duplicate Disk \"" arg1 "\" found in file \"" arg2 "\" on line " arg3 "."
    }
    else if (msgcode == "TgtDiskIsSrcDisk") # key, file
    {
	message[0] = "The target disk \"" arg1 "\" is also a source disk."
    }
    else if (msgcode == "InvalidValue") # field, file
    {
	message[0] = "Field \"" arg1 "\" must have a valid value in file \"" arg2 "\" on line " omp_linecnt "."
    }
    else if (msgcode == "TunableSyntax") # file, lineno
    {
	message[0] = "Errors detected while processing  \"" arg1 "\" fle on line " arg2 "." 
    }
    else if (msgcode == "FieldCount") # file, linecnt
    {
	message[0] = "The number of expected fields in file \"" arg1 "\"does not match on line " arg2 "."
    }
    else if (msgcode == "MatchedUp") # file
    {
	exitcode = EC_OK
	if (arg1 == 1)
	    message[0] ="There is only " arg1 " disk that matched up."
	else
	    message[0] ="There are " arg1 " disks that matched up."
    }
    else if (msgcode == "SourceCount") # file
    {
	exitcode = EC_OK
	if (arg1 == 1)
	    message[0] ="There is only " arg1 " disk in the source file."
	else
	    message[0] ="There are " arg1 " disks in the source file."
    }
    else if (msgcode == "TargetCount") # file
    {
	exitcode = EC_OK
	if (arg1 == 1)
	    message[0] ="There is only " arg1 " disk in the target file."
	else
	    message[0] ="There are " arg1 " disks in the target file."
    }
    else if (msgcode == "DosFormat") # file
    {
	exitcode = EC_WARN
	message[0] ="File \"" arg1 "\" is in DOS format."
    }
    else if (msgcode == "NoMigration") # schedule_group
    {
	message[0] = "No migration devices are available for a migration."
    }
    else
    {
	message[0] = "Cannot find message for message code \"" msgcode "\" \"" arg1 "\" \"" arg2 "\" \"" arg3 "\""
	msgcode = "OMP_MISSINGMSG"
    }
    if (exitcode == EC_OK)
    {
	severity = "INFO: "
    }
    else if (exitcode == EC_WARN)
    {
	severity = "WARNING: "
    }
    else if (exitcode == EC_ERROR)
    {
	severity = "ERROR: "
    }
    else if (exitcode == EC_FATAL)
    {
	severity = "FATAL: "
    }
    timestamp = strftime( "%Y.%m.%d--%T" )

    for (idx = 0; (idx in message); idx++)
    {
	if (discard_output !~ / no_std /)
	{
	    print severity message[idx]  " [" msgcode "]"
	}
	if (discard_output !~ / no_log /)
	{
	    print "[" timestamp "] " "genconf[" PROCINFO["pid"] "] " severity message[idx]  " [" msgcode "]" >> omp_logpath
	}
    }
    close (omp_logpath)
    if (exitcode > EC_WARN)
	exit( exitcode )
}

function GetTunables(   ot_status, ot_line, ot_nf, pos1, pos2, variable, value, linecnt )
{
    linecnt = 0
    ot_status = 1
    ot_status = getline ot_line < omp_tunablespath
    close( omp_tunablespath )
    if (ot_status < 0)
    {
	return
    }

    while (ot_status > 0)
    {
	ot_status = getline ot_line < omp_tunablespath
	linecnt++

	if (ot_status < 0)
	{
	    Display( "ReadError", omp_tunablespath, linecnt )
	}

	if (ot_status == 0 )
	{
	    close( omp_tunablespath )
	    break
	}

	sub(/\r$/,"", ot_line)

	# Ignore empty lines

	if (ot_line ~ /^([ \t]*,)*([ \t])*$/)
	{
	    ot_line = ""
	}

	if (ot_line == "" )
	{
	    continue
	}

	if (ot_line ~ /^[ \t]*#|^"[ \t]*#/)
	{
	    continue
	}
	pos1=index( ot_line, "=" )
	pos2=index( ot_line, "\"" )
	if (pos1 == 0 || (pos2 > 0 && pos1 > pos2))
	{
	    Display( "TunableSyntax", omp_tunablespath, linecnt )
	    continue
	}
	variable=substr(ot_line, 1, pos1 - 1)
	value=substr(ot_line, pos1 + 1)
	sub( /^[ \t]+/, "", variable )
	sub( /[ \t]+$/, "", variable )
	sub( /^[ \t]+/, "", value )
	sub( /[ \t]+$/, "", value )

	if (variable ~ /DebugMatchUp/)
	{
	    value = ShStringToNumber( value )
	    if (value == "!")
	    {
		Display( "TunableSyntax", omp_tunablespath, linecnt )
		continue
	    }
	}
    }
}

function ShStringToNumber( cvtstr,   num, numarray, n, negate, numstr, base, digit, value )
{

    gsub(/[ \t]+/,"", cvtstr)
    negate=0
    num=0
    if (cvtstr ~ /^-/)
    {
	cvtstr=substr(cvtstr, 2)
	negate=1
    }

    n = split( cvtstr, numarray, /#/ )
    if (n == 1)
    {
	base=10
	numstr=numarray[1]
    }
    else if (n == 2)
    {
	if (numarray[1] ~ /^[0-9]+$/)
	{
	    base=numarray[1] + 0
	}
	else
	{
	    return "!"
	}
	if (base > 36 || base < 2)
	{
	    return "!"
	}
	numstr=numarray[2]
    }
    else
    {
	return "!"
    }
    digit="!"
    for (n=1; n <= length(numstr); n++)
    {
	digit=substr(numstr,n,1)
	if (digit in DigitToValue)
	{
	    value = DigitToValue[digit]
	    if (negate)
	    {
		value = -value
	    }
	    num = num * base + value
	}
	else
	{
	    return "!"
	}
    }
    if (digit == "!")
    {
	return "!"
    }
    return num
}

#**************************************************************************
#
# In the event of an error -1 is returned and csv_error is set to the error.
# Parameters:
# string  = The string to parse.
# csv     = The array to parse the fields into.
# option  = option array for controling the csv parsing.  The function
#	    csv_set_default_option sets the option array with default values
#
#   option["separator"] = pattern
#
#	Defines the separator string between fields.  It may be a regular
#	expression.  Remember to use the rules for string regexp constants
#
#   option["quote-pattern"] = pattern
#
#	Defines the quote string for fields. The quote string used for a field
#	is determined by string matched when looking for a the beginning of a
#	field.
#
#   option["trim-record"] = "LEFT|RIGHT|BOTH|NONE"
#
#	The input string will be trimmed before the parsing for csv fields.
#
#   option["trim-field"] = "LEFT|RIGHT|BOTH|NONE"
#
#	The fields will be trimmed after all the fields have been determined. 
#
#   option["trim-pattern] = pattern
#
#	The trim regular expression used when trimming fields or records
#
#   option["quote-pattern] = pattern
#
#	The quote regular expression used when determining if fields
#	begin with a quote.
#	Examples: "\"", "'|\""
#
#   option["quote-escape"] = DOUBLE|string
#
#	The escape character used to escape the quote character for quoted
#	fields. If the word DOUBLE used then the found field quote is
#	doubled.  Otherwise the value is the string for the escape quote.
#	It is assumed the escape qoute can be doubled.
#
#   option["embedded-newline"] = "string|<empty_string>" 
#
#	Allows for embedded newlines in files.  Normally the input string
#	is the complete csv record.  Set this value to the record separator
#	string.  When the parser comes to the end of a quoted string and 
#	no ending quote was found, the function csv_getline will be called
#	to get the next part of the input record
#
#   option["getline-param"]= ""
#
#	A user defined value to assist the csv_getline function to determine
#	which csv file is being processed.  
#
#**************************************************************************


function csv_set_default_option( csv_option ) 
{
    csv_option["separator"] = ","
    csv_option["quote-pattern"] = "\""
    csv_option["trim-record"] = "NONE"
    csv_option["trim-field"] = "NONE"
    csv_option["trim-pattern"] = "[ \\t]+"
    csv_option["quote-escape"] = "DOUBLE"
    csv_option["embedded-newline"] = "" 
    csv_option["getline-param"]= ""
}


#
# csv_getline
#
# This function returns the next csv line if embedded newlines are supported
# Modify this function to return the next csv line
#
# The return value defined the same way as getline.
#
#   -1 read error
#    0 end of file
#    1 line being returned
#
# The csv line is returned through line[0] array element.
# 
# The arg parameter  is caller defined value settable through the option array
# It is meant to assist in determining the proper csv that needs to be read.
#
function csv_getline( param, line ) 
{
    line[0] = ""
    return -1
}

function csv_parse(string, csv_field, csv_option,    csv_fields, pattern, pos, len, fld_quote, csv_line, temp )
{

    if (csv_option["trim-record"] ~/LEFT|BOTH/)
    {
	pattern = "^(" csv_option["trim-pattern"] ")"
	sub( pattern, "", string )
    }

    if (csv_option["trim-record"] ~ /RIGHT|BOTH/)
    {
	pattern = "(" csv_option["trim-pattern"] ")$"
	sub( pattern, "", string )
    }
	    
    split( "", csv_field)		 # clear out field array
    csv_fields = 0

    # Make sure there is something to parse.
    if (length(string) == 0) return 0;

    pattern = csv_option["quote-pattern"]
    if (string !~ pattern) 
    {
	pattern = csv_option["separator"]
	# print "debug doing split processing" 
	csv_fields = split( string, csv_field, pattern )
    }
    else
    {
	# print "debug doing quote processing" 
	csv_fields = 0
	while (length(string) > 0)
	{
	    pattern = "^(" csv_option["quote-pattern"] ")"

	    if (match(string, pattern))		# handle quoted string
	    {
		fld_quote = substr( string, RSTART, RLENGTH )
		string = substr( string, RLENGTH + 1 )

		# print "debug found start quote |" string "|"

		#
		# Attempt to escape \ and | when building the escape
		# pattern string. Should escape all regexp metacharacters
		# 

		pattern = toupper( csv_option["quote-escape"] )
		if (pattern == "DOUBLE")
		{
		    pattern = fld_quote fld_quote
		    gsub( /\\/, "\\\\", pattern )
		    gsub( /\|/, "\\|", pattern )
		}
		else
		{
		    pattern = csv_option["quote-escape"] fld_quote
		    gsub( /\\/, "\\\\", pattern )
		    gsub( /\|/, "\\|", pattern )
		    pattern = pattern "|"

		    temp = csv_option["quote-escape"] csv_option["quote-escape"]
		    gsub( /\\/, "\\\\", temp )
		    gsub( /\|/, "\\|", temp )
		    pattern = pattern temp
		}

		# print "debug pattern " pattern
		csv_fields++
		csv_field[csv_fields] = ""
		while (length(string) > 0)
		{
		    pos = 0
		    len = -1

		    if (match( string, pattern ))
		    {
			pos = RSTART
			len = RLENGTH
		    }
		    if (match( string, fld_quote ))
		    {
			if (pos == 0 || RSTART < pos) 
			{
			    # Found the end of the string.
			    if (RSTART -1 > 0)
			    {
				csv_field[csv_fields] = csv_field[csv_fields] substr( string, 1, RSTART - 1)
			    }
			    if (length(string) > RSTART + RLENGTH)
			    {
				string = substr( string, RSTART + RLENGTH )
			    }
			    else
			    {
				string = ""
			    }
			    # print "debug found end quote |" string "|"
			    pos = 0
			    len = -1
			    break
			}
		    }
		    if (pos > 0)
		    {
			if (pos - 1 > 0)
			{
			    csv_field[csv_fields] = csv_field[csv_fields] substr( string, 1, pos - 1)
			}
			csv_field[csv_fields] = csv_field[csv_fields] substr( string, pos + 1, len - 1 )
			string = substr( string, pos + len )
			# print "debug found escaped quote |" string "|"
		    }
		    else
		    {
			csv_field[csv_fields] = csv_field[csv_fields]  string
			string = ""
			if (csv_option["embedded-newline"])
			{
			    csv_line[0] = ""
			    pos = csv_getline( csv_option["getline-param"], csv_line )

			    if (pos <= 0)
			    {
				if (pos == 0)
				    csv_error = "Missing end quote.";
				else
				    csv_error = "Unable to read the next line" 
				return -1
			    }
			    string = csv_option["embedded-newline"] csv_line[0]
			}
			else
			{
			    csv_error = "Missing end quote.";
			    return -1;
			}
		    }
		}

		if (length( string ) == 0)
		{
		    # print "debug found end of record |" string "|"
		    break;
		}

		pattern = "^(" csv_option["separator"] ")"
		if (match( string, pattern ))
		{
		    string = substr( string, RLENGTH + 1 )
		    # print "debug found separator |" string "|"

		    if (length( string ) == 0)
		    {
			csv_fields++
			csv_field[csv_fields] = ""
			# print "debug found end of record |" string "|"
			break
		    }
		}
		else
		{
		    csv_error = "Missing Separator.";
		    return -1;
		}
	    }
	    else	# handle unquoted field
	    {

		# print "debug found unquoted string |" string "|"
		pattern = csv_option["separator"]
		if (match( string, pattern ))
		{
		    csv_fields++
		    csv_field[csv_fields] = substr( string, 1, RSTART - 1 )

		    string = substr( string, RSTART + RLENGTH  )
		    # print "debug found separator |" string "|"

		    if (length( string ) == 0)
		    {
			csv_fields++
			csv_field[csv_fields] = ""
			break
		    }
		}
		else		# last unquoted field
		{
		    csv_fields++;
		    csv_field[csv_fields] = string
		    break
		}
	    }
	}
    }

    if (csv_fields > 0)
    {
	if (csv_option["trim-field"] ~/LEFT|BOTH/)
	{
	    pattern = "^" csv_option["trim-pattern"]
	    for (pos in csv_field) sub( pattern, "", csv_field[pos] )
	}

	if (csv_option["trim-field"] ~ /RIGHT|BOTH/)
	{
	    pattern = csv_option["trim-pattern"] "$"
	    {
		for (pos in csv_field) sub( pattern, "", csv_field[pos] )
	    }
	}
    }
    return csv_fields;
}

function InitializeConstants()
{
    discard_output=""
    do_crosscheck=1
    omp_homedir = "/etc/opt/SFTKomp"
    omp_logdir = omp_homedir "/log"
    omp_jobsdir = omp_homedir "/jobs"
    omp_prepdir = omp_jobsdir "/staging" 
    omp_sandir = omp_jobsdir "/san"
    omp_srcfile = "source.omp"
    omp_tgtfile = "target.omp"
    omp_srccsvfile = "source.csv"
    omp_tgtcsvfile = "target.csv"
    omp_mupfile = "matchup.csv"
    omp_logfile = "omp_matchup.log"
    omp_tunablesfile="omp_tunables"
    omp_separator = ","
    FS=omp_separator
    omp_tunablespath  = omp_homedir "/" omp_tunablesfile
    omp_source = omp_sandir "/" omp_srcfile
    omp_target = omp_sandir "/" omp_tgtfile
    omp_matchup = omp_sandir "/" omp_mupfile
    omp_sourcecsv = omp_sandir "/" omp_srccsvfile
    omp_targetcsv = omp_sandir "/" omp_tgtcsvfile
    omp_logpath = omp_logdir "/" omp_logfile

    fldname_srcprefix = "src_"
    fldname_tgtprefix = "tgt_"
    fldname_serial = "serial#"
    fldname_serial80 = "serial#x80"

    #
    # Return codes
    #

    EC_TRAP=8
    EC_FATAL=4
    EC_ERROR=2
    EC_WARN=1
    EC_OK=0

    GetTunables()
}


function GetMatchFieldNames( header,    idx, mup_nf, srcidx, tgtidx, tidx, tmp )
{
    srcidx = 0
    tgtidx = 0

    /* Separate out the source and target matching columns */
    /* and create the field index for the matchup csv file */

    for (idx=1; idx <= expected_mup_nf; idx++)
    {
	if (header[idx] ~ /^src_/)
	{
	   sub( /^src_/, "", header[idx] )
	   srcidx++;
	   src_fldname[srcidx] = header[idx]
	   mup_srcidx[srcidx] = idx;
	}
	else if (header[idx] ~ /tgt_/)
	{
	   sub( /^tgt_/, "", header[idx] )
	   tgtidx++;
	   tgt_fldname[tgtidx] = header[idx]
	   mup_tgtidx[tgtidx] = idx;
	}
	else
	{
	    Display( "InvalidColName", header[idx], omp_matchup )
	}
    }

    if (srcidx == 0)
    {
	Display( "NoSrcCols", omp_matchup )
    }
    if (tgtidx == 0)
    {
	Display( "NoTgtCols", omp_matchup )
    }

    /* Reorder fields to make sure checking a source against target works */

    if (srcidx == tgtidx)
    {
	for (idx = 1; idx <= srcidx; idx++)
	{
	    if (src_fldname[idx] != tgt_fldname[idx])
	    {
		for(tidx = idx+1; tidx <= tgtidx; tidx++)
		{
		    if (src_fldname[idx] == tgt_fldname[tidx])
		    {
			tmp = tgt_fldname[idx]
			tgt_fldname[idx] = tgt_fldname[tidx]
			tgt_fldname[tidx] = tmp
			tmp = mup_tgtidx[idx]
			mup_tgtidx[idx] = mup_tgtidx[tidx]
			mup_tgtidx[tidx] = tmp
			break;
		    }
		}
		if (tidx > tgtidx)
		{
		    Display( "CrossCheck", src_fldname[idx] )
		    do_crosscheck = 0
		    break;
		}
	    }
	}
    }
    else
    {
	Display( "NoCrossCheck" )
	do_crosscheck = 0
    }
    return 0
}


function GetFieldIndex( fldname, header,     idx )
{
    for (idx in header)
    {
	if (header[idx] == fldname)
	{
	    return idx
	}
    }
    return 0
}


function InitializeIndices(    idx)
{
    for (idx in src_fldname)
    {
	src_fldidx[idx] = GetFieldIndex( src_fldname[idx], src_header ) 
	if (src_fldidx[idx] == 0)
	{
	    Display( "MissingField", src_fldname[idx], omp_source ) 
	}
	src_altfldidx[idx] = GetFieldIndex( src_fldname[idx], src_header ) 
	if (src_fldname[idx] == fldname_serial)
	{
	    src_altfldidx[idx] = GetFieldIndex( fldname_serial80, src_header ) 
	}
	if (src_altfldidx[idx] == 0)
	{
	    Display( "MissingField", src_fldname[idx], omp_source ) 
	}
    }

    for (idx in tgt_fldname)
    {
	tgt_fldidx[idx] = GetFieldIndex( tgt_fldname[idx], tgt_header ) 
	if (tgt_fldidx[idx] == 0)
	{
	    Display( "MissingField", tgt_fldname[idx], omp_target ) 
	}
	tgt_altfldidx[idx] = GetFieldIndex( tgt_fldname[idx], tgt_header ) 
	if (tgt_fldname[idx] == fldname_serial)
	{
	    tgt_altfldidx[idx] = GetFieldIndex( fldname_serial80, tgt_header ) 
	}
	if (tgt_altfldidx[idx] == 0)
	{
	    Display( "MissingField", tgt_fldname[idx], omp_target ) 
	}
    }
}


function ReadSourceOmp(   fldkey, idx, errkey )
{
    while(src_status > 0)
    {
	src_status = getline src_line < omp_source
	src_linecnt++
	if (src_status < 0)
	{
	    Display( "ReadError", omp_source, src_linecnt )
	}

	if (src_status == 0)
	{
	    --src_linecnt
	    break;
	}

	sub(/\r$/,"", src_line)

	if (src_line ~ /^([ \t]*,)*([ \t])*$/)
	{
	    src_line = ""
	}

	# Ignore empty lines

	if (src_line == "")
	{
	    continue
	}

	# Ignore comment lines

	if (src_line ~ /^[ \t]*#|^"[ \t]*#/)
	{
	    continue
	}

	src_nf = csv_parse( src_line, src_fields, omp_csv_option );

	if (expected_src_nf != src_nf)
	{
	    Display("FieldCount", omp_source, src_linecnt )
	}

	fldkey=""
	for (idx in src_fldidx)
	{
	    if (fldkey == "")
		fldkey = src_fields[src_fldidx[idx]]
	    else
		fldkey = fldkey SUBSEP src_fields[src_fldidx[idx]]
	}
	if (fldkey in SourceDisk)
	{
	    errkey = fldkey
	    gsub( SUBSEP, ", ", errkey ) 
	    Display( "DuplicateDisk", errkey, omp_source, src_linecnt )
	}
	SourceDisk[fldkey] = src_line
	altfldkey=""
	for (idx in src_altfldidx)
	{
	    if (altfldkey == "")
		altfldkey = src_fields[src_altfldidx[idx]]
	    else
		altfldkey = altfldkey SUBSEP src_fields[src_altfldidx[idx]]
	}
	if (altfldkey != fldkey)
	{
	    SourceKeyMap[altfldkey] = fldkey
	}
    }
    close( omp_source )
    Display( "SourceCount", (src_linecnt - 1) );
    return 0
}


function ReadTargetOmp(   fldkey, idx, errkey)
{
    while(tgt_status > 0)
    {
	tgt_status = getline tgt_line < omp_target
	tgt_linecnt++
	if (tgt_status < 0)
	{
	    Display( "ReadError", omp_target, tgt_linecnt )
	}

	if (tgt_status == 0)
	{
	    --tgt_linecnt
	    break
	}

	sub(/\r$/,"", tgt_line)

	if (tgt_line ~ /^([ \t]*,)*([ \t])*$/)
	{
	    tgt_line = ""
	}

	# Ignore empty lines

	if (tgt_line == "")
	{
	    continue
	}

	# Ignore comment lines

	if (tgt_line ~ /^[ \t]*#|^"[ \t]*#/)
	{
	    continue
	}

	tgt_nf = csv_parse( tgt_line, tgt_fields, omp_csv_option );

	if (expected_tgt_nf != tgt_nf)
	{
	    Display("FieldCount", omp_target, tgt_linecnt )
	}

	fldkey=""
	for (idx in tgt_fldidx)
	{
	    if (fldkey == "")
		fldkey = tgt_fields[tgt_fldidx[idx]]
	    else
		fldkey = fldkey SUBSEP tgt_fields[tgt_fldidx[idx]]
	}
	if (fldkey in TargetDisk)
	{
	    errkey = fldkey
	    gsub( SUBSEP, ", ", errkey ) 
	    Display( "DuplicateDisk", errkey, omp_target, tgt_linecnt )
	}
	if (do_crosscheck && fldkey in SourceDisk)
	{
	    errkey = fldkey
	    gsub( SUBSEP, ", ", errkey ) 
	    Display( "TgtDiskIsSrcDisk", errkey )
	}
	TargetDisk[fldkey] = tgt_line

	altfldkey=""
	for (idx in tgt_altfldidx)
	{
	    if (altfldkey == "")
		altfldkey = tgt_fields[tgt_altfldidx[idx]]
	    else
		altfldkey = altfldkey SUBSEP tgt_fields[tgt_altfldidx[idx]]
	}
	if (altfldkey != fldkey)
	{
	    TargetKeyMap[altfldkey] = fldkey
	}
    }

    close( omp_target )
    Display( "TargetCount", (tgt_linecnt - 1) );
    return 0
}


function CreateCsvFiles(    csv_linecnt, idx, errkey, src_disk_used, tgt_disk_used )
{
    csv_linecnt = 0
    while(mup_status > 0)
    {
	mup_status = getline mup_line < omp_matchup
	mup_linecnt++
	if (mup_status < 0)
	{
	    Display( "ReadError", omp_matchup, mup_linecnt )
	}

	if (mup_status == 0)
	{
	    --mup_linecnt
	    break
	}

	sub(/\r$/,"", mup_line)

	if (mup_line ~ /^([ \t]*,)*([ \t])*$/)
	{
	    mup_line = ""
	}

	# Ignore empty lines

	if (mup_line == "")
	{
	    continue
	}

	# Ignore comment lines

	if (mup_line ~ /^[ \t]*#|^"[ \t]*#/)
	{
	    continue
	}

	mup_nf = csv_parse( mup_line, mup_fields, omp_csv_option );

	if (expected_mup_nf != mup_nf)
	{
	    Display("FieldCount", omp_matchup, mup_linecnt )
	}

	mup_src_key=""
	src_key=""
	for (idx in mup_srcidx)
	{
	    if (src_key == "")
		src_key = mup_fields[mup_srcidx[idx]]
	    else
		src_key = src_key SUBSEP mup_fields[mup_srcidx[idx]]
	}
	mup_src_key = src_key

	mup_tgt_key=""
	tgt_key=""
	for (idx in mup_tgtidx)
	{
	    if (tgt_key == "")
		tgt_key = mup_fields[mup_tgtidx[idx]]
	    else
		tgt_key = tgt_key SUBSEP mup_fields[mup_tgtidx[idx]]
	}
	mup_tgt_key = tgt_key

	if (!(src_key in SourceDisk))
	{
	    if (!(src_key in SourceKeyMap))
	    {
		errkey = mup_src_key
		gsub( SUBSEP, ", ", errkey ) 
		Display( "DiskNotFound", errkey, omp_source )
	    }
	    src_key = SourceKeyMap[src_key]
	}
	if (src_key in src_disk_used)
	{
	    errkey = mup_src_key
	    gsub( SUBSEP, ", ", errkey ) 
	    Display( "DiskAlreadyUsed", errkey, omp_source )
	}
	src_disk_used[src_key] = 1

	if (!(tgt_key in TargetDisk))
	{
	    if (!(tgt_key in TargetKeyMap))
	    {
		errkey = mup_tgt_key
		gsub( SUBSEP, ", ", errkey ) 
		Display( "DiskNotFound", errkey, omp_target )
	    }
	    tgt_key = TargetKeyMap[tgt_key]
	}
	if (tgt_key in tgt_disk_used)
	{
	    errkey = mup_tgt_key
	    gsub( SUBSEP, ", ", errkey ) 
	    Display( "DiskAlreadyUsed", errkey, omp_target )
	}
	tgt_disk_used[tgt_key] = 1

	if (csv_linecnt == 0)
	{
	    print TargetDisk["header"] > omp_targetcsv
	    print SourceDisk["header"] > omp_sourcecsv
	    csv_linecnt++
	}
	print TargetDisk[tgt_key] > omp_targetcsv
	print SourceDisk[src_key] > omp_sourcecsv
	csv_linecnt++
    }
    if (csv_linecnt)
    {
	close(omp_targetcsv)
	close(omp_sourcecsv)
	Display( "MatchedUp", (csv_linecnt - 1))
    }
    else
    {
	Display( "NoCsvFiles" )
    }
    close( omp_matchup )
    return 0
}

BEGIN \
{
    DigitToValue["0"] = 0
    DigitToValue["1"] = 1
    DigitToValue["2"] = 2
    DigitToValue["3"] = 3
    DigitToValue["4"] = 4
    DigitToValue["5"] = 5
    DigitToValue["6"] = 6
    DigitToValue["7"] = 7
    DigitToValue["8"] = 8
    DigitToValue["9"] = 9
    DigitToValue["a"] = 10
    DigitToValue["b"] = 11
    DigitToValue["c"] = 12
    DigitToValue["d"] = 13
    DigitToValue["e"] = 14
    DigitToValue["f"] = 15
    DigitToValue["g"] = 16
    DigitToValue["h"] = 17
    DigitToValue["i"] = 18
    DigitToValue["j"] = 19
    DigitToValue["k"] = 20
    DigitToValue["l"] = 21
    DigitToValue["m"] = 22
    DigitToValue["n"] = 23
    DigitToValue["o"] = 24
    DigitToValue["p"] = 25
    DigitToValue["q"] = 26
    DigitToValue["r"] = 27
    DigitToValue["s"] = 28
    DigitToValue["t"] = 29
    DigitToValue["u"] = 30
    DigitToValue["v"] = 31
    DigitToValue["w"] = 32
    DigitToValue["x"] = 33
    DigitToValue["y"] = 34
    DigitToValue["z"] = 35
    DigitToValue["A"] = 10
    DigitToValue["B"] = 11
    DigitToValue["C"] = 12
    DigitToValue["D"] = 13
    DigitToValue["E"] = 14
    DigitToValue["F"] = 15
    DigitToValue["G"] = 16
    DigitToValue["H"] = 17
    DigitToValue["I"] = 18
    DigitToValue["J"] = 19
    DigitToValue["K"] = 20
    DigitToValue["L"] = 21
    DigitToValue["M"] = 22
    DigitToValue["N"] = 23
    DigitToValue["O"] = 24
    DigitToValue["P"] = 25
    DigitToValue["Q"] = 26
    DigitToValue["R"] = 27
    DigitToValue["S"] = 28
    DigitToValue["T"] = 29
    DigitToValue["U"] = 30
    DigitToValue["V"] = 31
    DigitToValue["W"] = 32
    DigitToValue["X"] = 33
    DigitToValue["Y"] = 34
    DigitToValue["Z"] = 35
    InitializeConstants()

    csv_set_default_option( omp_csv_option )

    mup_status = getline mup_line < omp_matchup
    if (mup_status <= 0)
	Display( "ReadError", omp_matchup, omp_muplinecnt )

    if (sub(/\r$/,"", mup_line))
	Display( "DosFormat", omp_matchup )

    expected_mup_nf = csv_parse( mup_line, mup_header, omp_csv_option )

    mup_linecnt = 1
    GetMatchFieldNames( mup_header )

    src_status = getline src_line < omp_source
    if (src_status <= 0)
	Display( "ReadError", omp_source, src_linecnt )

    if (sub(/\r$/,"", src_line))
	Display( "DosFormat", omp_source )

    src_linecnt = 1

    expected_src_nf = csv_parse( src_line, src_header, omp_csv_option )
    SourceDisk["header"] = src_line
    
    tgt_status = getline tgt_line < omp_target
    if (tgt_status <= 0)
	Display( "ReadError", omp_target, tgt_linecnt )

    if (sub(/\r$/, "", tgt_line))
	Display( "DosFormat", omp_target )

    tgt_linecnt = 1

    expected_tgt_nf = csv_parse( tgt_line, tgt_header, omp_csv_option );
    TargetDisk["header"] = tgt_line

    InitializeIndices()

    ReadSourceOmp()
    ReadTargetOmp()
    CreateCsvFiles()

    exit( EC_OK )
}
